{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPCG-Generator-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiO0ALHr1ej78FnQ6J9DnC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhi-Code-AI/SPCG-Comprehension-Generator/blob/main/notebooks/SPCG_Generator_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgNIX2M5s_a0",
        "outputId": "9295bea3-ac33-47c3-d50c-b4b3ab567062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh Khusrau, the river of love runs in strange directions.\r\n",
            "One who jumps into it drowns, and one who drowns, gets across.\r\n",
            "1\r\n",
            "The creaking of the chain of Majnun is the orchestra of the lovers,\r\n",
            "To appreciate its music is quite beyond the ears of the\n",
            "\n",
            "\n",
            "Unique entities: 59\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "train_file = tf.keras.utils.get_file(\"poetry.txt\",\"https://storage.googleapis.com/kagglesdsdata/datasets/974990/1648795/forms/couplet/CoupletPoemsCoupletPoembyAmirKhusro.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220830%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220830T074909Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=521365fbe701eef7a75e72f594cb0c4370deb434568a7726b0d22b2ea8329fc0ade5c0b9be40b4d025dc25b929beabb807fe80f8d910c6be07f62bc1b35fcd101f059308d0276ff7046d46f7d87eee3cfd27e5d9f6c388d15f8d7a2e9b396df2e87ccd9585d4a7e83ad689d40283ef5d362c2d92862097e1278edc1cbab653c142bf877f6dc6f7b5c2de4dd1b86f2a8cd0e6ed9790a2336b314f96e721313b791fcfc925d9b963307dc0c0d92bbf4acc7f02ac5520d2d1f20c5eb9e130797b38df01afe22b4427df81dfb5eb422b8219ca6c37f985982006977db2237457a397191b10c37e46540348988a1d7edfe56db5b296681b21b105c76c2f0f4bafa8f6\")\n",
        "train_file = open(train_file,'rb').read().decode(encoding='utf-8')\n",
        "print(train_file[:250])\n",
        "vocab = sorted(set(train_file))\n",
        "print(\"\\n\\nUnique entities: {}\".format(len(vocab)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tf.keras.layers.StringLookup(vocabulary=list(vocab),mask_token=None)\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def ids_to_text(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids),axis=-1)\n",
        "\n",
        "main_ids = ids(tf.strings.unicode_split(train_file,'UTF-8'))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(main_ids)\n",
        "seq_len = 40\n",
        "seq = dataset.batch(seq_len+1)\n",
        "\n",
        "def split_seq(seq):\n",
        "  input_seq = seq[:-1]\n",
        "  target_seq = seq[1:]\n",
        "  return input_seq,target_seq\n",
        "\n",
        "dataset = seq.map(split_seq)\n",
        "for i,t in dataset.take(1):\n",
        "  print(\"\\n\\nInput Sequence: {}\".format(ids_to_text(i).numpy()))\n",
        "  print(\"\\n\\nTarget Sequence: {}\".format(ids_to_text(t).numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hErjhZ_RvTGG",
        "outputId": "75d6ddbb-42b6-45c1-b949-b769b77e4521"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Input Sequence: b'Oh Khusrau, the river of love runs in st'\n",
            "\n",
            "\n",
            "Target Sequence: b'h Khusrau, the river of love runs in str'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_LEN = 10\n",
        "BUFF_SIZE = 10000\n",
        "dataset = (\n",
        "    dataset.shuffle(BUFF_SIZE).batch(BATCH_LEN,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "for i,t in dataset.take(1):\n",
        "  print(i)\n",
        "  print(t)\n",
        "\n",
        "vocab_size = len(ids.get_vocabulary())\n",
        "embedding_dim = 255\n",
        "rnn_units = 980"
      ],
      "metadata": {
        "id": "Y9NSvY9t04c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPredictionModel(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,embedding_dim,rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
        "    self.lstm = tf.keras.layers.GRU(rnn_units,return_sequences=True,return_state=True) \n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "  \n",
        "  def call(self,inputs,states=None,return_state=False,training=False):\n",
        "    inputs = self.embedding(inputs,training=training)\n",
        "    if states is None:\n",
        "      states = self.lstm.get_initial_state(inputs)\n",
        "    inputs,states = self.lstm(inputs,initial_state=states,training=training)\n",
        "    inputs = self.dense(inputs,training=training)\n",
        "    if return_state:\n",
        "        return inputs,states\n",
        "    else:\n",
        "      return inputs\n",
        "\n",
        "model = TextPredictionModel(vocab_size=vocab_size,embedding_dim=embedding_dim,\n",
        "                            rnn_units=rnn_units)\n",
        "\n",
        "for i,t in dataset.take(1):\n",
        "  batch_pred = model(i)\n",
        "  print(batch_pred.shape)    \n",
        "\n",
        "model.summary()   "
      ],
      "metadata": {
        "id": "nwAzLYIv48bR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}